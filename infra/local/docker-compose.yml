

services:
  # ======================
  # Redis
  # ======================
  redis:
    container_name: genai_redis
    image: redis:latest
    ports:
      - "6380:6379"
    networks:
      - gen-ai-med-chat
    restart: always

  # ======================
  # Qdrant
  # ======================
  qdrant:
    container_name: genai_qdrant
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    networks:
      - gen-ai-med-chat
    restart: always
    volumes:
      - qdrant_data:/qdrant/storage

  # ======================
  # MongoDB
  # ======================
  mongo:
    container_name: genai_mongo
    image: mongo:7
    ports:
      - "27017:27017"
    networks:
      - gen-ai-med-chat
    restart: always
    healthcheck:
      test: [ "CMD", "mongosh", "--eval", "db.adminCommand('ping')" ]
      interval: 10s
      timeout: 5s
      retries: 5

  # ======================
  # Backend - User Service
  # ======================
  user_service:
    container_name: genai_user_service
    build:
      context: ..
      dockerfile: backend/app/services/user_service/Dockerfile
    labels:
      com.centurylinklabs.watchtower.enable: "true"
    ports:
      - "8001:8001"
    command: >
      uvicorn user_service.main:app --host 0.0.0.0 --port 8001
      --reload --reload-dir /app/services/user_service/user_service --reload-dir /app/shared
    environment:
      MONGO_URI: mongodb://genai_mongo:27017
      MONGO_DB: genai_med
      OTEL_EXPORTER_OTLP_ENDPOINT: http://tempo:4318
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: http://tempo:4318/v1/traces
      OTEL_EXPORTER_OTLP_PROTOCOL: http/protobuf
      OTEL_SERVICE_NAME: user_service
    depends_on:
      mongo:
        condition: service_healthy
    networks:
      - gen-ai-med-chat
    restart: always
    volumes:
      - ../backend/app/services/user_service/user_service:/app/services/user_service/user_service
      - ../backend/app/shared:/app/shared

  # ======================
  # Backend - Gateway Service
  # ======================
  gateway:
    container_name: genai_gateway
    build:
      context: ..
      dockerfile: backend/app/gateway/Dockerfile
    labels:
      com.centurylinklabs.watchtower.enable: "true"
    ports:
      - "8000:8000"
    command: >
      uvicorn gateway.main:app --host 0.0.0.0 --port 8000
      --reload --reload-dir /app/gateway/gateway --reload-dir /app/shared
    depends_on:
      qdrant:
        condition: service_started
    environment:
      CHAT_SERVICE_URL: http://genai_chat_service:8003
      USER_SERVICE_URL: http://genai_user_service:8001
      PRODUCT_SERVICE_URL: http://genai_product_service:8082
      OTEL_EXPORTER_OTLP_ENDPOINT: http://tempo:4318
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: http://tempo:4318/v1/traces
      OTEL_EXPORTER_OTLP_PROTOCOL: http/protobuf
      OTEL_SERVICE_NAME: gateway
    networks:
      - gen-ai-med-chat
    restart: always
    volumes:
      - ../backend/app/gateway/gateway:/app/gateway/gateway
      - ../backend/app/shared:/app/shared

  # ======================
  # Backend - Chat Service
  # ======================
  chat_service:
    container_name: genai_chat_service
    build:
      context: ..
      dockerfile: backend/app/services/chat_service/Dockerfile
    labels:
      com.centurylinklabs.watchtower.enable: "true"
    ports:
      - "8003:8003"
    command: >
      uvicorn chat_service.main:app --host 0.0.0.0 --port 8003
      --reload --reload-dir /app/services/chat_service/chat_service --reload-dir /app/shared
    depends_on:
      mongo:
        condition: service_healthy
      qdrant:
        condition: service_started
      ai_service:
        condition: service_started
    environment:
      MONGO_URI: mongodb://genai_mongo:27017
      MONGO_DB: genai_med
      QDRANT_URL: http://genai_qdrant:6333
      AI_SERVICE_URL: http://genai_ai_service:8004
      OTEL_EXPORTER_OTLP_ENDPOINT: http://tempo:4318
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: http://tempo:4318/v1/traces
      OTEL_EXPORTER_OTLP_PROTOCOL: http/protobuf
      OTEL_SERVICE_NAME: chat_service
    networks:
      - gen-ai-med-chat
    restart: always
    volumes:
      - ../backend/app/services/chat_service/chat_service:/app/services/chat_service/chat_service
      - ../backend/app/shared:/app/shared

  # ======================
  # Backend - AI Service
  # ======================
  ai_service:
    container_name: genai_ai_service
    build:
      context: ..
      dockerfile: backend/app/services/ai_service/Dockerfile
    labels:
      com.centurylinklabs.watchtower.enable: "true"
    env_file:
      - ./env/.env
    ports:
      - "8004:8004"
    command: >
      uvicorn ai_service.main:app --host 0.0.0.0 --port 8004
      --reload --reload-dir /app/services/ai_service/ai_service --reload-dir /app/shared
    environment:
      OTEL_EXPORTER_OTLP_ENDPOINT: http://tempo:4318
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: http://tempo:4318/v1/traces
      OTEL_EXPORTER_OTLP_PROTOCOL: http/protobuf
      OTEL_SERVICE_NAME: ai_service
      LANGCHAIN_TRACING_V2: "true"
      LANGCHAIN_PROJECT: genai-med-chat
    networks:
      - gen-ai-med-chat
    restart: always
    volumes:
      - ../backend/app/services/ai_service/ai_service:/app/services/ai_service/ai_service
      - ../backend/app/shared:/app/shared

  # ======================
  # Backend - Celery Worker
  # ======================
  worker:
    container_name: genai_worker
    build:
      context: ..
      dockerfile: backend/worker/Dockerfile
    labels:
      com.centurylinklabs.watchtower.enable: "true"
    command: ["python", "-m", "celery", "-A", "celery_worker.celery_app", "worker", "--loglevel=info"]
    environment:
      CELERY_BROKER_URL: redis://genai_redis:6379/0
      CELERY_RESULT_BACKEND: redis://genai_redis:6379/1
      CHAT_SERVICE_URL: http://genai_chat_service:8003
      OTEL_EXPORTER_OTLP_ENDPOINT: http://tempo:4318
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: http://tempo:4318/v1/traces
      OTEL_EXPORTER_OTLP_PROTOCOL: http/protobuf
      OTEL_SERVICE_NAME: worker
    depends_on:
      redis:
        condition: service_started
      chat_service:
        condition: service_started
    networks:
      - gen-ai-med-chat
    restart: always
    volumes:
      - backend_data:/data
      - ../backend/worker:/app/worker
      - ../backend/app/shared:/app/shared

  # ======================
  # Frontend
  # ======================
  frontend:
    container_name: genai_frontend
    build:
      context: ../frontend
      dockerfile: Dockerfile
      target: dev
    labels:
      com.centurylinklabs.watchtower.enable: "true"
    ports:
      - "5173:5173"
    environment:
      - NODE_ENV=development
      - VITE_API_BASE_URL=http://localhost:8000
      - CHOKIDAR_USEPOLLING=true
    command: ["npm", "--workspace", "packages/app", "run", "dev", "--", "--host", "0.0.0.0"]
    networks:
      - gen-ai-med-chat
    restart: always
    volumes:
      - ../frontend:/app
      - frontend-node-modules:/app/node_modules


    # ============================================================================
  
  # OBSERVABILITY LAYER
  # ============================================================================
  tempo:
    image: grafana/tempo:latest
    container_name: genai-coach-tempo
    command: ["-config.file=/etc/tempo.yaml"]
    user: "0:0"
    ports:
      - "3200:3200"
      - "4317:4317"
      - "4318:4318"
    volumes:
      - ./observability/tempo.yaml:/etc/tempo.yaml:ro
      - tempo-data:/tmp/tempo
    networks:
      - gen-ai-med-chat
    restart: unless-stopped

  loki:
    image: grafana/loki:latest
    container_name: genai-coach-loki
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./observability/loki-config.yaml:/etc/loki/local-config.yaml:ro
      - loki-data:/loki
    networks:
      - gen-ai-med-chat
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    container_name: genai-coach-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
      - '--web.enable-remote-write-receiver'    
    ports:
      - "9092:9090"
    volumes:
      - ./observability/prometheus.yaml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      - gen-ai-med-chat
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: genai-coach-grafana
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
    ports:
      - "3001:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./observability/grafana-datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml:ro
    depends_on:
      - tempo
      - loki
      - prometheus
    networks:
      - gen-ai-med-chat
    restart: unless-stopped

  promtail:
    image: grafana/promtail:latest
    container_name: genai-coach-promtail
    volumes:
      - ./observability/promtail-config.yaml:/etc/promtail/config.yml
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: -config.file=/etc/promtail/config.yml
    networks:
      - gen-ai-med-chat
    restart: unless-stopped


# ======================
# Volumes
# ======================
volumes:
  redis_data:
  qdrant_data:
  backend_data:
  tempo-data:
  loki-data:
  prometheus-data:
  grafana-data:
  frontend-node-modules:

# ======================
# Shared Network
# ======================
networks:
  gen-ai-med-chat:
    driver: bridge

